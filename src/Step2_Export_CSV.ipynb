{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bc63d19",
   "metadata": {},
   "source": [
    "# Strava Exports to CSV Files\n",
    "Now that all of our data is uncompressed, we have to transform all of the seperate files to something that can be loaded into a database. MySQL's `LOAD DATA INFILE` is quite efficient for bulk loading, so if we are able to transform the data for each table into a CSV file then loading the data should be more straightforward.\n",
    "\n",
    "As we get into going through data for various users it gets more difficult to keep track of what data is supposed to represent and who it belongs to, so I think an object oriented approach might be better. In the end, the strat may be to load all the data for each table into a pandas DataFrame, use the `pandas.to_csv()` method, and then import the generated CSVs into MySQL.\n",
    "\n",
    "For information and advice on the three filetypes used and their contents, this tutorial was heavily referenced: [Parsing fitness tracker data with Python](https://towardsdatascience.com/parsing-fitness-tracker-data-with-python-a59e7dc17418/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f2a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Package Imports, Constants, Global Variable\n",
    "\n",
    "Run this cell to import all the packages we need and define some constants. \n",
    "You'll likely need to install any missing packages to your Python environment\n",
    "with pip or your package manager of choice.\n",
    "'''\n",
    "\n",
    "import os\n",
    "import gpxpy\n",
    "import fitdecode\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "ACTIVITY_DIR_PATH = '../data/export_activities' # Parent directory of all exports\n",
    "cur_activity_id = 0   # Global activity counter to give each activity a unique id across users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73f73bd",
   "metadata": {},
   "source": [
    "Let's define an `Activity` object. We will use this object to store all the data from an individual file from an export, whether it is a .fit, .gpx, or .tcx file. By feeding the path to the activity file in the constructor, we are able to make an `Activity` create itself from a file when it is instantiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebbcb145",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activity:\n",
    "\n",
    "  __mysql_null = 'NULL'\n",
    "  __activity_summary_keys = ['user_id', 'activity_id', 'filename', \n",
    "                             'start_datetime', 'end_datetime', \n",
    "                             'distance_2d', 'distance_3d',\n",
    "                             'avg_speed', 'max_speed',\n",
    "                             'uphill', 'downhill',\n",
    "                             'avg_hr', 'min_hr', 'max_hr',\n",
    "                             'avg_cad','min_cad','max_cad',\n",
    "                             'total_kcal']\n",
    "\n",
    "  def __init__(self, activity_id: int, user_id: int, activity_filepath: os.PathLike):\n",
    "    self.__activity_id = activity_id\n",
    "    self.__user_id = user_id\n",
    "    self.__activity_filepath = activity_filepath\n",
    "    self.__points_df = pd.DataFrame()\n",
    "\n",
    "    self.__activity_summary = dict.fromkeys(self.__activity_summary_keys, self.__mysql_null)\n",
    "    self.__activity_summary.update({'user_id': self.__user_id, \n",
    "                                    'activity_id': self.__activity_id,\n",
    "                                    'filename': os.path.basename(self.__activity_filepath)})\n",
    "\n",
    "    self.__point_dict = {\n",
    "      'activity_id': [],\n",
    "      'latitude': [],\n",
    "      'longitude': [],\n",
    "      'elevation': [],\n",
    "      'time': [],\n",
    "      'speed': [],\n",
    "      'hr': [],\n",
    "      'cad': []\n",
    "    }\n",
    "\n",
    "    self.__load_from_file()\n",
    "    \n",
    "  def __load_from_file(self) -> None:\n",
    "    match self.__activity_filepath.split('.')[-1].lower():\n",
    "      case 'gpx':\n",
    "        self.__load_from_gpx()\n",
    "      case 'tcx':\n",
    "        self.__load_from_tcx()\n",
    "      case 'fit':\n",
    "        self.__load_from_fit()\n",
    "\n",
    "  def __load_from_gpx(self) -> None:\n",
    "\n",
    "    with open(self.__activity_filepath) as f:\n",
    "      gpx = gpxpy.parse(f)\n",
    "\n",
    "      uphill, downhill = 0, 0\n",
    "\n",
    "      if len(gpx.tracks) == 0:\n",
    "        raise ValueError(f'No tracks found in gpx file {os.path.abspath(self.__activity_filepath)}')\n",
    "\n",
    "      for track in gpx.tracks:\n",
    "\n",
    "        uphill_downhill = track.get_uphill_downhill()\n",
    "        uphill += uphill_downhill.uphill\n",
    "        downhill += uphill_downhill.downhill\n",
    "        \n",
    "        for segment in track.segments:\n",
    "          for point_idx, point in enumerate(segment.points):            \n",
    "            self.__point_dict['activity_id'].append(self.__activity_id)\n",
    "            self.__point_dict['time'].append(point.time)\n",
    "            self.__point_dict['latitude'].append(point.latitude)\n",
    "            self.__point_dict['longitude'].append(point.longitude)\n",
    "            self.__point_dict['elevation'].append(point.elevation)\n",
    "\n",
    "            # Adding speed\n",
    "            point_speed = point.speed\n",
    "            if point_idx == 0:\n",
    "              point_speed = 0\n",
    "            elif point_speed == None:\n",
    "              point_speed = point.speed_between(segment.points[point_idx - 1])\n",
    "            self.__point_dict['speed'].append(point_speed)\n",
    "\n",
    "            # Adding extensions\n",
    "            found_hr = False\n",
    "            found_cad = False\n",
    "            for extension in point.extensions:\n",
    "\n",
    "              hr_element = extension.find('{http://www.garmin.com/xmlschemas/TrackPointExtension/v1}hr')\n",
    "              cad_element = extension.find('{http://www.garmin.com/xmlschemas/TrackPointExtension/v1}cad')\n",
    "              \n",
    "              # Adding heart rate, if exists\n",
    "              if hr_element is not None and hr_element.text:\n",
    "                self.__point_dict['hr'].append(int(hr_element.text))\n",
    "                found_hr = True\n",
    "              \n",
    "              # Adding cadence, if exists\n",
    "              if cad_element is not None and cad_element.text:\n",
    "                self.__point_dict['cad'].append(int(cad_element.text))\n",
    "                found_cad = True\n",
    "            \n",
    "            # Adding nulls if cadence or heart rate don't exist\n",
    "            if not found_hr:\n",
    "              self.__point_dict['hr'].append('\\\\N')\n",
    "            if not found_cad:\n",
    "              self.__point_dict['cad'].append('\\\\N')\n",
    "      \n",
    "      # Creating the dataframe of points from the dictionary\n",
    "      self.__points_df = pd.DataFrame(self.__point_dict)\n",
    "\n",
    "      # Populating activity summary dictionary\n",
    "      timebounds = gpx.get_time_bounds()\n",
    "      self.__activity_summary.update({'start_datetime': timebounds.start_time,\n",
    "                                      'end_datetime': timebounds.end_time,\n",
    "                                      'distance_2d': round(gpx.length_2d(), 3),\n",
    "                                      'distance_3d': round(gpx.length_3d(), 3),\n",
    "                                      'avg_speed': round(self.__points_df['speed'].mean(), 3),\n",
    "                                      'max_speed': round(self.__points_df['speed'].max(), 3),\n",
    "                                      'uphill': round(uphill, 3),\n",
    "                                      'downhill': round(downhill, 3)})\n",
    "      \n",
    "      questionable_cols = ['hr', 'cad']\n",
    "      for col in questionable_cols:\n",
    "        if(self.__points_df[col].dtype == 'int64'):\n",
    "          self.__activity_summary.update({'avg_' + col: round(self.__points_df[col].mean(), 3),\n",
    "                                          'min_' + col: self.__points_df[col].min(),\n",
    "                                          'max_' + col: self.__points_df[col].max()})\n",
    "    \n",
    "\n",
    "    # Ensure activity_id is stored as integer\n",
    "    self.__points_df['activity_id'] = self.__points_df['activity_id'].astype(int)\n",
    "\n",
    "  # Stubs to be replaced with real file parsing code\n",
    "  def __load_from_tcx(self) -> None:\n",
    "    pass\n",
    "\n",
    "  def __load_from_fit(self) -> None:\n",
    "    pass\n",
    "\n",
    "  # Getter methods\n",
    "  def get_summary(self) -> dict:\n",
    "    return self.__activity_summary\n",
    "  \n",
    "  def get_points(self) -> pd.DataFrame:\n",
    "    return self.__points_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5debbcf",
   "metadata": {},
   "source": [
    "Now let's define a `User`. An entire export directory of activity files belongs to a Strava user, so our `User` can have a list of `Activities`. By feeding the path to the export directory into the constructor, a `User` is able to initialize itself with all of its `Activities` upon instantiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44c4315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "\n",
    "  def __init__(self, user_id: int, export_filepath: os.PathLike, name: str):\n",
    "    self.__user_id = user_id\n",
    "    self.__export_filepath = export_filepath\n",
    "    self.__name = name\n",
    "    self.__activities = []\n",
    "    self.__load_all_activities()\n",
    "\n",
    "  def __load_all_activities(self):\n",
    "    files = os.listdir(self.__export_filepath)\n",
    "    for file in files:\n",
    "      # Only process known file types\n",
    "      file_ext = file.split('.')[-1].lower()\n",
    "      if file_ext in ['gpx']:#, 'tcx', 'fit']:\n",
    "        try:\n",
    "          global cur_activity_id\n",
    "          self.__activities.append(Activity(activity_id = cur_activity_id, \n",
    "                                            user_id = self.__user_id, \n",
    "                                            activity_filepath = os.path.join(self.__export_filepath, file)))\n",
    "          cur_activity_id += 1\n",
    "        except ValueError as ve:\n",
    "          print(f'Error occured when loading {file}: {ve}')\n",
    "\n",
    "  # Getters for exporting\n",
    "  def get_activity_summaries(self) -> pd.DataFrame:\n",
    "    activity_summaries = [activity.get_summary() for activity in self.__activities]\n",
    "    return pd.DataFrame(activity_summaries)\n",
    "\n",
    "  def get_activity_points(self) -> pd.DataFrame:\n",
    "    point_dfs = [activity.get_points() for activity in self.__activities]\n",
    "    combined_df = pd.concat(point_dfs)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9d50dc",
   "metadata": {},
   "source": [
    "Let's test it out by initializing a `User`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e1f34e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occured when loading 7077892227.gpx: No tracks found in gpx file c:\\Users\\matth\\Documents\\Python\\CS3200\\CS3200_Strava_Secretary\\data\\export_activities\\export_101635319\\7077892227.gpx\n"
     ]
    }
   ],
   "source": [
    "steve = User(user_id = 1, export_filepath = '../data/export_activities/export_101635319', name='Steve')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dcc5b9",
   "metadata": {},
   "source": [
    "And let's look at the activities summaries CSV for this user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3873739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    user_id  activity_id        filename            start_datetime  \\\n",
      "0         1            0  6997176516.gpx 2022-04-17 14:16:52+00:00   \n",
      "1         1            1  7014531890.gpx 2022-04-20 19:42:28+00:00   \n",
      "2         1            2  7019748989.gpx 2022-04-21 19:44:08+00:00   \n",
      "3         1            3  7024451292.gpx 2022-04-22 19:48:17+00:00   \n",
      "4         1            4  7034624054.gpx 2022-04-24 15:34:29+00:00   \n",
      "5         1            5  7040713235.gpx 2022-04-25 20:15:24+00:00   \n",
      "6         1            6  7046031446.gpx 2022-04-26 20:21:17+00:00   \n",
      "7         1            7  7056695803.gpx 2022-04-28 20:14:49+00:00   \n",
      "8         1            8  7056695936.gpx 2022-04-28 20:29:28+00:00   \n",
      "9         1            9  7056725873.gpx 2022-04-28 20:59:31+00:00   \n",
      "10        1           10  7061409366.gpx 2022-04-29 19:48:46+00:00   \n",
      "11        1           11  7071266617.gpx 2022-05-01 15:12:59+00:00   \n",
      "12        1           12  7071443617.gpx 2022-05-01 15:23:21+00:00   \n",
      "13        1           13  7083497081.gpx 2022-05-03 20:15:25+00:00   \n",
      "14        1           14  7089537289.gpx 2022-05-04 18:53:18+00:00   \n",
      "\n",
      "                end_datetime  distance_2d  distance_3d  avg_speed  max_speed  \\\n",
      "0  2022-04-17 15:08:13+00:00    10005.202    10007.961      3.633      7.480   \n",
      "1  2022-04-20 20:47:05+00:00    12825.163    12826.533      3.567      8.001   \n",
      "2  2022-04-21 20:16:51+00:00     3348.415     3348.888      4.961      9.705   \n",
      "3  2022-04-22 20:26:48+00:00     4876.460     4877.151      3.848      5.862   \n",
      "4  2022-04-24 16:12:35+00:00     7786.426     7789.513      3.559      8.366   \n",
      "5  2022-04-25 20:58:44+00:00     8542.223     8543.379      3.311      5.218   \n",
      "6  2022-04-26 20:41:14+00:00     3917.686     3918.129      3.285      6.555   \n",
      "7  2022-04-28 20:26:05+00:00     1296.766     1297.009      2.691      4.728   \n",
      "8  2022-04-28 20:58:04+00:00     4416.086     4418.029      3.111     13.380   \n",
      "9  2022-04-28 21:10:25+00:00     1409.419     1409.966      2.491      3.940   \n",
      "10 2022-04-29 20:55:56+00:00    13264.821    13268.051      3.311      7.564   \n",
      "11 2022-05-01 15:23:14+00:00     2036.332     2036.384      3.300      4.224   \n",
      "12 2022-05-01 15:48:25+00:00     3407.977     3408.053      3.782      7.701   \n",
      "13 2022-05-03 20:46:18+00:00     6149.495     6150.349      3.417      9.156   \n",
      "14 2022-05-04 20:04:32+00:00     5368.406     5368.868      1.503      4.418   \n",
      "\n",
      "    uphill  downhill   avg_hr min_hr max_hr avg_cad min_cad max_cad total_kcal  \n",
      "0    33.83     32.63  182.136    138    192    NULL    NULL    NULL       NULL  \n",
      "1    50.22     49.92  182.364    136    189    NULL    NULL    NULL       NULL  \n",
      "2    17.53     17.73  172.389    133    194    NULL    NULL    NULL       NULL  \n",
      "3    26.51     26.61  176.813    123    196    NULL    NULL    NULL       NULL  \n",
      "4    66.32     78.02  181.199    146    191    NULL    NULL    NULL       NULL  \n",
      "5    34.42     34.52  170.807    164    179    NULL    NULL    NULL       NULL  \n",
      "6    16.54     15.84   162.68    143    176    NULL    NULL    NULL       NULL  \n",
      "7     9.84      5.34  141.204    118    160    NULL    NULL    NULL       NULL  \n",
      "8    62.44     56.64  164.522    137    191    NULL    NULL    NULL       NULL  \n",
      "9     9.66     15.56  156.466    140    167    NULL    NULL    NULL       NULL  \n",
      "10   79.11     80.81  169.785    157    182    NULL    NULL    NULL       NULL  \n",
      "11    2.73      5.33  158.087    116    168    NULL    NULL    NULL       NULL  \n",
      "12    7.11      5.71  176.545    113    195    NULL    NULL    NULL       NULL  \n",
      "13   29.06     29.36  171.687    121    182    NULL    NULL    NULL       NULL  \n",
      "14   11.64     11.14   88.179     75    107    NULL    NULL    NULL       NULL  \n"
     ]
    }
   ],
   "source": [
    "points_df = steve.get_activity_points()\n",
    "points_df.to_csv('../data/points.csv', index_label='seq_num', lineterminator='\\n')\n",
    "\n",
    "activities_df = steve.get_activity_summaries()\n",
    "print(activities_df.head(15))\n",
    "activities_df.to_csv('../data/activities_summaries.csv', index = False, lineterminator='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
