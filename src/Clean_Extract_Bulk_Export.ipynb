{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79f0d76a",
   "metadata": {},
   "source": [
    "# Strava Export Parsing\n",
    "Bulk Strava exports (obtained using the ['Bulk Export' instructions by Strava Support](https://support.strava.com/hc/en-us/articles/216918437-Exporting-your-Data-and-Bulk-Export)) come in the form of a large zipped file containing a variety of CSV and other files in the top-level folder, along with a few subdirectories (`activities`, `clubs`, `media`, and `routes`). Luckily for us, the majority of the CSVs and subdirectories are sparse or empty due to users not utilizing those features or contain data not directly relevant to activity logging, such as device identifiers, app login tracking, etc.\n",
    "##### **Which files do we actually care about?**\n",
    "In the `activities` subdirectory, there is a file for every action that is logged by Strava. These files are what we mainly care about, and they tend to come in two different flavors:\n",
    "- **FIT (.fit) or Compressed FIT (.fit.gz) Files**\\\n",
    "  FIT (Flexible and Interoperable data Transfer) is a [binary file type developed by Garmin](https://developer.garmin.com/fit/file-types/) that is a able to store a breadth of data recorded by a fitness tracker (check out the link for what sort of data can be stored in there!). These are binary files, which means that they are not human-readable even when uncompressed. We can use the [fitdecode Python library](https://pypi.org/project/fitdecode/) for reading and parsing these files after uncompressing them.\n",
    "\n",
    "- **GPX Files**\\\n",
    "  GPX (GPs eXchange format) is an open way to store location data such as waypoints and routes in an XML-based file format. XML is human-readable, which means we can view the raw data if desired. Although GPX focuses more on location data and can contains less descriptive activity information than a FIT file could, this data format is simpler and more widely used. We can use the [gpxpy Python library](https://pypi.org/project/gpxpy/) for reading and parsing GPX files.\n",
    "\n",
    "- **TCX Files**\\\n",
    "  TCX (Training Center XML) files are also there ¯\\\\\\_(ツ)\\_/¯\n",
    "\n",
    "This Jupyter Notebook aims to extract desired information from provided Strava bulk exports and load them into a MySQL relational schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1d3cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Package Imports and Constants\n",
    "\n",
    "Run this cell to import all the packages we need and define some constants. \n",
    "You'll likely need to install any missing packages to your Python environment\n",
    "with pip or your package manager of choice.\n",
    "'''\n",
    "\n",
    "import os                   # For navigating bulk export on filesystem\n",
    "import gzip                 # For uncompressing .gz files\n",
    "import shutil\n",
    "from zipfile import ZipFile # For uncompressing .zip files\n",
    "\n",
    "import fitdecode            # For .fit file parsing\n",
    "import gpxpy                # For .gpx file parsing\n",
    "\n",
    "\n",
    "DATA_DIR_PATH = '../data/'  # Path of data directory relative to this Jupyter Notebook\n",
    "ACTIVITY_DIR_PATH = os.path.join(DATA_DIR_PATH + 'export_activities')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5a3d4e",
   "metadata": {},
   "source": [
    "We don't want to manually extract all the data we want out of the compressed exports, so let's write some code to do that for us. We'll need a directory where we can expect to find all of our export files, let's say they're in a directory called `data` in the repository. Let's see what's in there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c825d3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files and directories in the data directory:\n",
      "\texport_101635319.zip\n",
      "\texport_148511532.zip\n",
      "\texport_57141745.zip\n",
      "\texport_96589216.zip\n",
      "Found 4 zips! Ready to extract.\n",
      "\tExtracting activities from zip 1 of 4 ...\n",
      "\tExtracting activities from zip 2 of 4 ...\n",
      "\tExtracting activities from zip 3 of 4 ...\n",
      "\tExtracting activities from zip 4 of 4 ...\n",
      "All zips extracted to '../data/export_activities'!\n"
     ]
    }
   ],
   "source": [
    "files_and_dirs = os.listdir(DATA_DIR_PATH)\n",
    "zip_archives = []\n",
    "\n",
    "# Let's see what's currently in the data directory\n",
    "print(\"Files and directories in the data directory:\")\n",
    "for entry in files_and_dirs:\n",
    "    print(f'\\t{entry}')\n",
    "    if (entry.split('.')[-1] == 'zip'):\n",
    "      zip_archives.append(entry)\n",
    "\n",
    "num_zips = len(zip_archives)\n",
    "print(f'Found {num_zips} zips! Ready to extract.')\n",
    "\n",
    "# Extracting the entire activity directory from each zip\n",
    "i = 1\n",
    "for entry in zip_archives:\n",
    "  print(f'\\tExtracting activities from zip {i} of {num_zips} ...')\n",
    "  with ZipFile(DATA_DIR_PATH + entry) as archive:\n",
    "      for file in archive.namelist():\n",
    "        if file.startswith('activities/'):\n",
    "          archive.getinfo(file).filename = entry.split('.')[0] + '/' + file.split('/')[-1]\n",
    "          archive.extract(file, ACTIVITY_DIR_PATH)\n",
    "  i += 1\n",
    "print(f'All zips extracted to \\'{ACTIVITY_DIR_PATH}\\'!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a24a6e",
   "metadata": {},
   "source": [
    "Nice, now we have the `activities` folder from each bulk export unpacked into a directory (of the same name as the export) in (`/data/export_activities`). But our work isn't done yet! Some of the activity files (.fit, .gpx, etc), have been compressed by gzip into .gz files, and we have to uncompress those too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f407c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 activity export directories!\n",
      "\tExtracting all activities from directory 1 of 4 ...\n",
      "\tExtracting all activities from directory 2 of 4 ...\n",
      "\tExtracting all activities from directory 3 of 4 ...\n",
      "\tExtracting all activities from directory 4 of 4 ...\n",
      "All gzips extracted in place!\n"
     ]
    }
   ],
   "source": [
    "# Getting the paths to all of the activity export directories\n",
    "activity_export_dirs = [os.path.join(ACTIVITY_DIR_PATH, entry) \n",
    "                        for entry \n",
    "                        in os.listdir(ACTIVITY_DIR_PATH) \n",
    "                        if os.path.isdir(os.path.join(ACTIVITY_DIR_PATH, entry))]\n",
    "num_activity_exports = len(activity_export_dirs)\n",
    "print(f'Found {num_activity_exports} activity export directories!')\n",
    "\n",
    "# Iterating through all files in each activity directory, \n",
    "# extracting the compressed ones and deleting their compressed versions\n",
    "i = 1\n",
    "for dir in activity_export_dirs:\n",
    "    print(f'\\tExtracting all activities in directory {i} of {num_activity_exports} ...')\n",
    "    gzipped_files = [os.path.join(dir, entry) \n",
    "                     for entry \n",
    "                     in os.listdir(dir) \n",
    "                     if entry.split('.')[-1] == 'gz']\n",
    "    for gzipped_file in gzipped_files:\n",
    "        with gzip.open(gzipped_file, 'rb') as f_in:\n",
    "            with open(os.path.splitext(gzipped_file)[0], 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        os.remove(gzipped_file)\n",
    "    i += 1\n",
    "print(f'All gzips extracted in place!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57e3bb5",
   "metadata": {},
   "source": [
    "Now we have all of the data we care about extracted in `data/export_activities/`! Each person's export is now a subdirectory composed of .fit, .gpx, or even .tcx files.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
